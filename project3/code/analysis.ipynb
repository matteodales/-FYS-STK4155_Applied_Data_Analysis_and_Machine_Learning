{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as skm\n",
    "import matplotlib.pyplot as plt\n",
    "from TreeBasedMethods import *\n",
    "from optimizer_functions import logistic_regression_sgd\n",
    "import seaborn as sns\n",
    "from activation_functions import *\n",
    "from optimizer_functions import *\n",
    "from cost_functions import *\n",
    "from Layer import Layer\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns list of all metrics given the predicted probability and real class\n",
    "\n",
    "def classification_metrics(prob_pred,y_test):\n",
    "\n",
    "    tn, fp, fn, tp = skm.confusion_matrix(y_test, prob_pred.round()).ravel()\n",
    "\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    fscore = 2*(precision*recall)/(precision+recall)\n",
    "    auc = skm.roc_auc_score(y_test, prob_pred)\n",
    "\n",
    "    return [acc, precision, recall, specificity, fscore, auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Pima Indians Diabetes dataset\n",
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing inaccurate values with mean\n",
    "df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n",
    "df['Glucose'].fillna(df['Glucose'].mean(), inplace = True)\n",
    "df['BloodPressure'].fillna(df['BloodPressure'].mean(), inplace = True)\n",
    "df['SkinThickness'].fillna(df['SkinThickness'].mean(), inplace = True)\n",
    "df['Insulin'].fillna(df['Insulin'].mean(), inplace = True)\n",
    "df['BMI'].fillna(df['BMI'].mean(), inplace = True)\n",
    "\n",
    "df = df.rename(columns={\"Pregnancies\": \"Preg\", 'BloodPressure': \"Press\", \"SkinThickness\": \"Skin\", \"DiabetesPedigreeFunction\": \"DPF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df.hist(figsize=(20, 20))\n",
    "[x.title.set_size(20) for x in fig.ravel()]\n",
    "plt.savefig(\"Variable histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "heatmap = sns.heatmap(df.corr(), annot=True,annot_kws={'fontsize':20})\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':20}, pad=12)\n",
    "heatmap.set_xticklabels(heatmap.get_xmajorticklabels(),fontsize=20)\n",
    "heatmap.set_yticklabels(heatmap.get_ymajorticklabels(),fontsize=20,rotation=0)\n",
    "plt.savefig(\"Correlation heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting in train and test \n",
    "\n",
    "X = df.drop('Outcome',axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler().fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison performance our implementation and sklearn\n",
    "\n",
    "y_train_comp = y_train.values*2-1\n",
    "y_test_comp = y_test.values*2-1\n",
    "\n",
    "clf = DecisionTreeClass(max_depth=200)\n",
    "clf.fit(X_train, y_train_comp)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test_comp, y_pred)\n",
    "\n",
    "print(\"Our implementation tree:\", acc)\n",
    "\n",
    "print(\"Sklearn tree:\", DecisionTreeClassifier(max_depth=200).fit(X_train,y_train).score(X_test,y_test))\n",
    "\n",
    "model = RandomForest(num_trees=200)\n",
    "model.fit(X_train, y_train_comp)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "acc = accuracy(y_test_comp, preds)\n",
    "\n",
    "print(\"Our implementation Random forest:\", acc)\n",
    "\n",
    "print(\"Sklearn Random forest:\", RandomForestClassifier(n_estimators=200).fit(X_train,y_train).score(X_test,y_test))\n",
    "\n",
    "model = AdaBoost()\n",
    "model.fit(X_train, y_train_comp, M=200)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "acc = accuracy(y_test_comp, preds)\n",
    "\n",
    "print(\"Our implementation AdaBoost:\", acc)\n",
    "\n",
    "print(\"Sklearn AdaBoost:\", AdaBoostClassifier(n_estimators=200).fit(X_train,y_train).score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning method's parameters and studying performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute train and test error for different values of cost-complexity parameter\n",
    "\n",
    "alphas = dec_tree.cost_complexity_pruning_path(X_train,y_train)['ccp_alphas']\n",
    "len_alphas = len(alphas)\n",
    "\n",
    "train_err_dec_tree = np.zeros(len_alphas)\n",
    "test_err_dec_tree = np.zeros(len_alphas)\n",
    "\n",
    "for i in range(len_alphas):\n",
    "    a = alphas[i]\n",
    "    dec_tree.ccp_alpha = a\n",
    "    dec_tree.fit(X_train,y_train)\n",
    "    train_err_dec_tree[i] = dec_tree.score(X_train,y_train)\n",
    "    test_err_dec_tree[i] = dec_tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(alphas,train_err_dec_tree, label = 'Training accuracy')\n",
    "plt.plot(alphas,test_err_dec_tree, label = 'Test accuracy')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlim((-0.002,0.04))\n",
    "plt.xlabel(\"Alpha\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy\", fontsize=15)\n",
    "plt.title(\"Train and test accuracy for classification tree\", fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig(\"Train and test accuracy for classification tree.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(ccp_alpha=0.006).fit(X_train,y_train)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plot_tree(dt,feature_names=df.columns,impurity=False, label='none', fontsize=11, filled=True)\n",
    "#plt.savefig(\"Pruned tree.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ensemble methods with increasing number of trees and unpruned tree\n",
    "\n",
    "unpruned_tree_acc = DecisionTreeClassifier().fit(X_train,y_train).score(X_test,y_test)\n",
    "\n",
    "ntrees_v = range(1,801,5)\n",
    "rf = RandomForestClassifier()\n",
    "ab = AdaBoostClassifier()\n",
    "\n",
    "test_err_rf = []\n",
    "test_err_ab = []\n",
    "\n",
    "for n in ntrees_v:\n",
    "\n",
    "    rf.n_estimators = int(n)\n",
    "    rf.fit(X_train,y_train)\n",
    "    test_err_rf.append(rf.score(X_test,y_test))\n",
    "\n",
    "    ab.n_estimators = int(n)\n",
    "    ab.fit(X_train,y_train)\n",
    "    test_err_ab.append(ab.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(ntrees_v,test_err_rf, label = 'Random Forest')\n",
    "plt.plot(ntrees_v,test_err_ab, label = 'Adaboost')\n",
    "plt.hlines(unpruned_tree_acc,-10,801, colors = 'green', label = 'Unpruned tree',linestyles='dashed')\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel(\"Number of trees\",fontsize=15)\n",
    "plt.ylabel(\"Accuracy\",fontsize=15)\n",
    "plt.title(\"Test accuracy for ensemble methods with different number of trees\",fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig(\"Test accuracy for ensemble methods with different number of trees.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy rf changing number of predictors at each split\n",
    "\n",
    "n_vars = range(1,9)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "test_err_rf = []\n",
    "\n",
    "for n in n_vars:\n",
    "\n",
    "    rf.max_features = n\n",
    "    rf.fit(X_train,y_train)\n",
    "    test_err_rf.append(rf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(n_vars,test_err_rf)\n",
    "plt.xlabel(\"Number of predictors at each split\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy\", fontsize=15)\n",
    "plt.title(\"Random Forest changing number of predictors considered at each split\", fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig(\"Random Forest changing number of predictors considered at each split.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curves\n",
    "\n",
    "dt = DecisionTreeClassifier(ccp_alpha=0.006).fit(X_train,y_train)\n",
    "dt_probs = dt.predict_proba(X_test)[:,1]\n",
    "dt_fpr, dt_tpr, _ = skm.roc_curve(y_test, dt_probs)\n",
    "dt_roc_auc = skm.roc_auc_score(y_test, dt_probs)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "rf_probs = rf.predict_proba(X_test)[:,1]\n",
    "rf_fpr, rf_tpr, _ = skm.roc_curve(y_test, rf_probs)\n",
    "rf_roc_auc = skm.roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "ab = AdaBoostClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "ab_probs = ab.predict_proba(X_test)[:,1]\n",
    "ab_fpr, ab_tpr, _ = skm.roc_curve(y_test, ab_probs)\n",
    "ab_roc_auc = skm.roc_auc_score(y_test, ab_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(dt_fpr,dt_tpr,color=\"darkorange\",label=\"Decision tree (AUC = %0.2f)\" % dt_roc_auc)\n",
    "plt.plot(rf_fpr,rf_tpr,color=\"green\",label=\"Random forest (AUC = %0.2f)\" % rf_roc_auc)\n",
    "plt.plot(ab_fpr,ab_tpr,color=\"red\",label=\"AdaBoost (AUC = %0.2f)\" % ab_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\",fontsize=15)\n",
    "plt.ylabel(\"True Positive Rate\",fontsize=15)\n",
    "plt.title(\"ROC curve for tree-based methods\",fontsize=15)\n",
    "plt.legend(loc=\"lower right\",fontsize=15)\n",
    "#plt.savefig(\"ROC curve for tree-based methods.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable importance with random forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "rf_importances = rf.feature_importances_\n",
    "rf_std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.bar(X.columns,rf_importances, yerr=rf_std)\n",
    "plt.xticks(rotation=60,fontsize=15)\n",
    "plt.xlabel(\"\",fontsize=15)\n",
    "plt.ylabel(\"Relative importance\",fontsize=15)\n",
    "plt.title(\"Variable importance from Random Forest ensemble\",fontsize=15)\n",
    "plt.savefig(\"Variable importance from Random Forest ensemble.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics table with all variables: Accuracy (%) Precision (%) Sensitivity (%) Specificity (%) F-score (%) AUC (%)\n",
    "\n",
    "dt_metrics = classification_metrics(dt.predict_proba(X_test)[:,1],y_test)\n",
    "rf_metrics = classification_metrics(rf.predict_proba(X_test)[:,1],y_test)\n",
    "ab_metrics = classification_metrics(ab.predict_proba(X_test)[:,1],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F-Score', 'AUC'])\n",
    "metrics_table.loc['Decision Tree'] = dt_metrics\n",
    "metrics_table.loc['Random Forest'] = rf_metrics\n",
    "metrics_table.loc['AdaBoost'] = ab_metrics\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics selecting 2 variables (Glucose and BMI)\n",
    "\n",
    "X_train_2 = X_train[:,[1,5]]\n",
    "X_test_2 = X_test[:,[1,5]]\n",
    "\n",
    "dt_2 = DecisionTreeClassifier(ccp_alpha=0.01).fit(X_train_2,y_train)\n",
    "rf_2 = RandomForestClassifier(n_estimators=100).fit(X_train_2,y_train)\n",
    "ab_2 = AdaBoostClassifier(n_estimators=100).fit(X_train_2,y_train)\n",
    "\n",
    "dt_2_metrics = classification_metrics(dt_2,X_test_2,y_test)\n",
    "rf_2_metrics = classification_metrics(rf_2,X_test_2,y_test)\n",
    "ab_2_metrics = classification_metrics(ab_2,X_test_2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table_2 = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F-Score', 'AUC'])\n",
    "metrics_table_2.loc['Decision Tree'] = dt_2_metrics\n",
    "metrics_table_2.loc['Random Forest'] = rf_2_metrics\n",
    "metrics_table_2.loc['AdaBoost'] = ab_2_metrics\n",
    "metrics_table_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search best parameters logistic regression\n",
    "\n",
    "# tuning learning rate and regularization parameter\n",
    "\n",
    "y_train_log = y_train.values\n",
    "y_test_log = y_test.values\n",
    "\n",
    "eta_list = [0.001, 0.01, 0.02, 0.05, 0.07, 0.09]\n",
    "reg_list = [0, 0.01, 0.1, 1, 10]\n",
    "accuracy_mat = np.zeros((len(reg_list),len(eta_list)))\n",
    "\n",
    "for j in range(len(eta_list)):\n",
    "    for i in range(len(reg_list)):\n",
    "       \n",
    "        reg = reg_list[i]\n",
    "        eta = eta_list[j]\n",
    "\n",
    "        betas = logistic_regression_sgd(X_train, y_train_log, eta, reg, 200, 50)\n",
    "        ypred = (sigmoid(X_test @ betas)>=0.5)\n",
    "        accuracy_mat[i][j] = sum(y_test_log == ypred)/np.shape(y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "heatmap = sns.heatmap(accuracy_mat, xticklabels=eta_list, yticklabels=reg_list, annot=True, annot_kws={\"size\": 20}, fmt=\".3f\")\n",
    "plt.ylabel(\"Regularization parameter\", fontsize=20)\n",
    "plt.xlabel(\"Learning rate\", fontsize=20)\n",
    "heatmap.set_xticklabels(heatmap.get_xmajorticklabels(),fontsize=20)\n",
    "heatmap.set_yticklabels(heatmap.get_ymajorticklabels(),fontsize=20,rotation=0)\n",
    "plt.title(\"Accuracy grid search for learning rate and regularization parameter for logistic regression\", fontsize=20)\n",
    "#plt.savefig(\"logreg_accuracy_lr_nn_grid_search.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning learning rate and regularization parameter\n",
    "\n",
    "y_train_nn = y_train.values.reshape(len(y_train),1)\n",
    "y_test_nn = y_test.values.reshape(len(y_test),1)\n",
    "\n",
    "eta_list = [0.001, 0.01, 0.02, 0.05, 0.075]\n",
    "reg_list = [0, 0.01, 0.1, 1, 10]\n",
    "accuracy_mat_nn = np.zeros((len(reg_list),len(eta_list)))\n",
    "\n",
    "for j in range(len(eta_list)):\n",
    "    for i in range(len(reg_list)):\n",
    "       \n",
    "        reg = reg_list[i]\n",
    "        eta = eta_list[j]\n",
    "\n",
    "        nn = NeuralNetwork(8, class_cost_grad,random_state=1)\n",
    "        layer1 = Layer(30, sigmoid, sigmoid_grad)\n",
    "        layer2 = Layer(1, sigmoid, sigmoid_grad)\n",
    "        nn.add_layer(layer1)\n",
    "        nn.add_layer(layer2)\n",
    "        nn.train(X_train,y_train_nn,eta=eta,regularization=reg, epochs=100)\n",
    "\n",
    "        pred = nn.feed_forward_out(X_test)\n",
    "        pred = pred.round()\n",
    "        accuracy_mat_nn[i][j] = np.sum(pred == y_test_nn)/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "heatmap = sns.heatmap(accuracy_mat_nn, xticklabels=eta_list, yticklabels=reg_list, annot=True, annot_kws={\"size\": 20}, fmt=\".3f\")\n",
    "plt.ylabel(\"Regularization parameter\", fontsize=20)\n",
    "plt.xlabel(\"Learning rate\", fontsize=20)\n",
    "heatmap.set_xticklabels(heatmap.get_xmajorticklabels(),fontsize=20)\n",
    "heatmap.set_yticklabels(heatmap.get_ymajorticklabels(),fontsize=20,rotation=0)\n",
    "plt.title(\"Accuracy grid search for learning rate and regularization parameter\", fontsize=20)\n",
    "#plt.savefig(\"accuracy_grid_search.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning learning rate and number of neurons\n",
    "\n",
    "eta_list = [0.001, 0.01, 0.02, 0.05, 0.075]\n",
    "n_neurons_list = [10, 20, 30, 50]\n",
    "accuracy_mat_nn = np.zeros((len(eta_list),len(n_neurons_list)))\n",
    "\n",
    "for j in range(len(eta_list)):\n",
    "    for i in range(len(n_neurons_list)):\n",
    "       \n",
    "        n_neurons = n_neurons_list[i]\n",
    "        eta = eta_list[j]\n",
    "\n",
    "        nn = NeuralNetwork(8,class_cost_grad,random_state=1)\n",
    "        layer1 = Layer(n_neurons, sigmoid, sigmoid_grad)\n",
    "        layer2 = Layer(1, sigmoid, sigmoid_grad)\n",
    "        nn.add_layer(layer1)\n",
    "        nn.add_layer(layer2)\n",
    "        nn.train(X_train,y_train_nn,eta=eta, epochs=200)\n",
    "\n",
    "        pred = nn.feed_forward_out(X_test)\n",
    "        pred = pred.round()\n",
    "        accuracy_mat_nn[j][i] = np.sum(pred == y_test_nn)/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "heatmap = sns.heatmap(accuracy_mat_nn.T, xticklabels=eta_list, yticklabels=n_neurons_list, annot=True, annot_kws={\"size\": 20}, fmt=\".3f\")\n",
    "plt.ylabel(\"Number of neurons\", fontsize=20)\n",
    "plt.xlabel(\"Learning rate\", fontsize=20)\n",
    "heatmap.set_xticklabels(heatmap.get_xmajorticklabels(),fontsize=20)\n",
    "heatmap.set_yticklabels(heatmap.get_ymajorticklabels(),fontsize=20,rotation=0)\n",
    "plt.title(\"Accuracy grid search for learning rate and number of neurons\", fontsize=20)\n",
    "#plt.savefig(\"accuracy_lr_nn_grid_search.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different number of hidden layers\n",
    "\n",
    "n_epochs = 100\n",
    "eta = 0.05\n",
    "step = 5\n",
    "\n",
    "nn_1 = NeuralNetwork(8,class_cost_grad,random_state=1)\n",
    "nn_2 = NeuralNetwork(8,class_cost_grad,random_state=1)\n",
    "nn_3 = NeuralNetwork(8,class_cost_grad,random_state=1)\n",
    "layer11 = Layer(20,sigmoid,sigmoid_grad)\n",
    "layer21 = Layer(1,sigmoid,sigmoid_grad)\n",
    "layer12 = Layer(20,sigmoid,sigmoid_grad)\n",
    "layer22 = Layer(20,sigmoid,sigmoid_grad)\n",
    "layer32 = Layer(1,sigmoid,sigmoid_grad)\n",
    "layer13 = Layer(20,sigmoid,sigmoid_grad)\n",
    "layer23 = Layer(20,sigmoid,sigmoid_grad)\n",
    "layer33 = Layer(20,sigmoid,sigmoid_grad)\n",
    "layer43 = Layer(1,sigmoid,sigmoid_grad)\n",
    "\n",
    "nn_1.add_layer(layer11)\n",
    "nn_1.add_layer(layer21)\n",
    "nn_2.add_layer(layer12)\n",
    "nn_2.add_layer(layer22)\n",
    "nn_2.add_layer(layer32)\n",
    "nn_3.add_layer(layer13)\n",
    "nn_3.add_layer(layer23)\n",
    "nn_3.add_layer(layer33)\n",
    "nn_3.add_layer(layer43)\n",
    "\n",
    "acc_1 = []\n",
    "acc_2 = []\n",
    "acc_3 = []\n",
    "\n",
    "\n",
    "for i in range(0,n_epochs,step):\n",
    "    \n",
    "    acc_1.append(np.sum(nn_1.feed_forward_out(X_test).round() == y_test_nn)/y_test_nn.shape[0])\n",
    "    acc_2.append(np.sum(nn_2.feed_forward_out(X_test).round() == y_test_nn)/y_test_nn.shape[0])\n",
    "    acc_3.append(np.sum(nn_3.feed_forward_out(X_test).round() == y_test_nn)/y_test_nn.shape[0])\n",
    "    nn_1.train(X_train,y_train_nn,eta=eta,epochs=step, minibatch_size = 20)\n",
    "    nn_2.train(X_train,y_train_nn,eta=eta,epochs=step, minibatch_size = 20)\n",
    "    nn_3.train(X_train,y_train_nn,eta=eta,epochs=step, minibatch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(0,n_epochs,step),acc_1,label='1 hidden layer')\n",
    "plt.plot(range(0,n_epochs,step),acc_2,label='2 hidden layers')\n",
    "plt.plot(range(0,n_epochs,step),acc_3,label='3 hidden layers')\n",
    "plt.legend(fontsize=15)\n",
    "plt.title(\"Accuracy vs Epochs\", fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy\", fontsize=15)\n",
    "#plt.savefig(\"class_number_of_hidden_layers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different activation functions\n",
    "\n",
    "n_epochs = 200\n",
    "step = 5\n",
    "eta = 0.05\n",
    "\n",
    "nn_sigm = NeuralNetwork(8, class_cost_grad,random_state=1)\n",
    "nn_relu = NeuralNetwork(8, class_cost_grad,random_state=1)\n",
    "nn_lrelu = NeuralNetwork(8, class_cost_grad,random_state=1)\n",
    "nn_tanh = NeuralNetwork(8, class_cost_grad,random_state=1)\n",
    "layer1sigm = Layer(20,sigmoid,sigmoid_grad)\n",
    "layer2sigm= Layer(1,sigmoid,sigmoid_grad)\n",
    "layer1relu = Layer(20,ReLU,ReLU_grad)\n",
    "layer2relu = Layer(1,sigmoid,sigmoid_grad)\n",
    "layer1lrelu = Layer(20,leakyReLU,leakyReLU_grad)\n",
    "layer2lrelu = Layer(1,sigmoid,sigmoid_grad)\n",
    "layer1tanh = Layer(20,tanh,tanh_grad)\n",
    "layer2tanh = Layer(1,sigmoid,sigmoid_grad)\n",
    "nn_sigm.add_layer(layer1sigm)\n",
    "nn_sigm.add_layer(layer2sigm)\n",
    "nn_relu.add_layer(layer1relu)\n",
    "nn_relu.add_layer(layer2relu)\n",
    "nn_lrelu.add_layer(layer1lrelu)\n",
    "nn_lrelu.add_layer(layer2lrelu)\n",
    "nn_tanh.add_layer(layer1tanh)\n",
    "nn_tanh.add_layer(layer2tanh)\n",
    "\n",
    "acc_sigm = []\n",
    "acc_relu = []\n",
    "acc_lrelu = []\n",
    "acc_tanh = []\n",
    "\n",
    "for i in range(0,n_epochs,step):\n",
    "    acc_sigm.append(np.sum(nn_sigm.feed_forward_out(X_test).round() == y_test_nn)/y_test.shape[0])\n",
    "    acc_relu.append(np.sum(nn_relu.feed_forward_out(X_test).round() == y_test_nn)/y_test.shape[0])\n",
    "    acc_lrelu.append(np.sum(nn_lrelu.feed_forward_out(X_test).round() == y_test_nn)/y_test.shape[0])\n",
    "    acc_tanh.append(np.sum(nn_tanh.feed_forward_out(X_test).round() == y_test_nn)/y_test.shape[0])\n",
    "    nn_sigm.train(X_train,y_train_nn,eta=eta,epochs=step)\n",
    "    nn_relu.train(X_train,y_train_nn,eta=eta,epochs=step)\n",
    "    nn_lrelu.train(X_train,y_train_nn,eta=eta,epochs=step)\n",
    "    nn_tanh.train(X_train,y_train_nn,eta=eta,epochs=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(0,n_epochs,step),acc_sigm,label='Sigmoid')\n",
    "plt.plot(range(0,n_epochs,step),acc_relu,label='ReLU')\n",
    "plt.plot(range(0,n_epochs,step),acc_lrelu,label='Leaky ReLU')\n",
    "plt.plot(range(0,n_epochs,step),acc_tanh,label='Tanh')\n",
    "plt.legend(fontsize=15)\n",
    "plt.title(\"Test accuracy vs Epochs for different activation functions\", fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy\", fontsize=15)\n",
    "#plt.savefig(\"class_nn_activation_functions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curves\n",
    "\n",
    "betas = logistic_regression_sgd(X_train, y_train_log, 0.001, 1, 200, 50)\n",
    "lr_probs = sigmoid(X_test @ betas)\n",
    "lr_fpr, lr_tpr, _ = skm.roc_curve(y_test, lr_probs)\n",
    "lr_roc_auc = skm.roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "nn = NeuralNetwork(8, class_cost_grad, random_state=1)\n",
    "layer1 = Layer(20, sigmoid, sigmoid_grad)\n",
    "layer2 = Layer(20, sigmoid, sigmoid_grad)\n",
    "layer3 = Layer(1, sigmoid, sigmoid_grad)\n",
    "nn.add_layer(layer1)\n",
    "nn.add_layer(layer2)\n",
    "nn.add_layer(layer3)\n",
    "nn.train(X_train, y_train_nn, eta=0.05, epochs=200)\n",
    "nn_probs = nn.feed_forward_out(X_test)\n",
    "nn_fpr, nn_tpr, _ = skm.roc_curve(y_test, nn_probs)\n",
    "nn_roc_auc = skm.roc_auc_score(y_test, nn_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(dt_fpr,dt_tpr,color=\"darkorange\",label=\"Logistic Regression (AUC = %0.2f)\" % lr_roc_auc)\n",
    "plt.plot(rf_fpr,rf_tpr,color=\"green\",label=\"Neural Network (AUC = %0.2f)\" % nn_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\",fontsize=15)\n",
    "plt.ylabel(\"True Positive Rate\",fontsize=15)\n",
    "plt.title(\"ROC curves for Neural Network and Logistic Regression\",fontsize=15)\n",
    "plt.legend(loc=\"lower right\",fontsize=15)\n",
    "plt.savefig(\"ROC curves for Neural Network and Logistic Regression.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics = classification_metrics(lr_probs,y_test)\n",
    "nn_metrics = classification_metrics(nn_probs,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F-Score', 'AUC'])\n",
    "metrics_table.loc['Decision Tree'] = dt_metrics\n",
    "metrics_table.loc['Random Forest'] = rf_metrics\n",
    "metrics_table.loc['AdaBoost'] = ab_metrics\n",
    "metrics_table.loc['Logistic Regression'] = lr_metrics\n",
    "metrics_table.loc['Neural Network'] = nn_metrics\n",
    "metrics_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('uni')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "418c59836fa3b9ce9db29957e801ce461de12293cee0e24ddf0e9f7bd846be9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
